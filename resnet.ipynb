{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in ./env/lib/python3.11/site-packages (22.0.2)\n",
            "Collecting pip\n",
            "  Downloading pip-22.3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 22.0.2\n",
            "    Uninstalling pip-22.0.2:\n",
            "      Successfully uninstalled pip-22.0.2\n",
            "Successfully installed pip-22.3.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade pip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nnVt5MMqR3V",
        "outputId": "0df480f3-9401-48c3-9a6b-b0b8867a70b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting opencv-python\n",
            "  Using cached opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.0/578.0 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:03\u001b[0m\n",
            "\u001b[?25hCollecting numpy>=1.19.3\n",
            "  Using cached numpy-1.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "Requirement already satisfied: packaging in ./env/lib/python3.10/site-packages (from tensorflow) (21.3)\n",
            "Collecting libclang>=13.0.0\n",
            "  Downloading libclang-14.0.6-py2.py3-none-manylinux2010_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
            "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.10.26-py2.py3-none-any.whl (26 kB)\n",
            "Collecting h5py>=2.9.0\n",
            "  Downloading h5py-3.7.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting absl-py>=1.0.0\n",
            "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 KB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-preprocessing>=1.1.1\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=3.6.6\n",
            "  Using cached typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
            "Collecting google-pasta>=0.1.1\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 KB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.11,>=2.10.0\n",
            "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 KB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
            "  Downloading grpcio-1.50.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in ./env/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
            "Collecting termcolor>=1.1.0\n",
            "  Downloading termcolor-2.1.0-py3-none-any.whl (5.8 kB)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.27.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.11,>=2.10.0\n",
            "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in ./env/lib/python3.10/site-packages (from tensorflow) (59.6.0)\n",
            "Collecting wrapt>=1.11.0\n",
            "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 KB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 KB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard<2.11,>=2.10\n",
            "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m0m\n",
            "\u001b[?25hCollecting astunparse>=1.6.0\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Collecting protobuf<3.20,>=3.9.2\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting wheel<1.0,>=0.23.0\n",
            "  Downloading wheel-0.38.4-py3-none-any.whl (36 kB)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0mm\n",
            "\u001b[?25hCollecting werkzeug>=1.0.1\n",
            "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.7/232.7 KB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting requests<3,>=2.21.0\n",
            "  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "Collecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 KB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
            "  Downloading google_auth-2.14.1-py2.py3-none-any.whl (175 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 KB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 KB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./env/lib/python3.10/site-packages (from packaging->tensorflow) (3.0.9)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
            "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0\n",
            "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Collecting idna<4,>=2.5\n",
            "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
            "Collecting certifi>=2017.4.17\n",
            "  Using cached certifi-2022.9.24-py3-none-any.whl (161 kB)\n",
            "Collecting charset-normalizer<3,>=2\n",
            "  Using cached charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Using cached urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "Collecting MarkupSafe>=2.1.1\n",
            "  Using cached MarkupSafe-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting pyasn1<0.5.0,>=0.4.6\n",
            "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 KB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboard-plugin-wit, pyasn1, libclang, keras, flatbuffers, wrapt, wheel, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, pyasn1-modules, protobuf, oauthlib, numpy, MarkupSafe, markdown, idna, grpcio, google-pasta, gast, charset-normalizer, certifi, cachetools, absl-py, werkzeug, requests, opt-einsum, opencv-python, keras-preprocessing, h5py, google-auth, astunparse, requests-oauthlib, google-auth-oauthlib, tensorboard, tensorflow\n",
            "Successfully installed MarkupSafe-2.1.1 absl-py-1.3.0 astunparse-1.6.3 cachetools-5.2.0 certifi-2022.9.24 charset-normalizer-2.1.1 flatbuffers-22.10.26 gast-0.4.0 google-auth-2.14.1 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.50.0 h5py-3.7.0 idna-3.4 keras-2.10.0 keras-preprocessing-1.1.2 libclang-14.0.6 markdown-3.4.1 numpy-1.23.4 oauthlib-3.2.2 opencv-python-4.6.0.66 opt-einsum-3.3.0 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.28.1 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.27.0 termcolor-2.1.0 typing-extensions-4.4.0 urllib3-1.26.12 werkzeug-2.2.2 wheel-0.38.4 wrapt-1.14.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install opencv-python tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in ./env/lib/python3.10/site-packages (from matplotlib) (21.3)\n",
            "Collecting cycler>=0.10\n",
            "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./env/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
            "Collecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (296 kB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.1/296.1 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fonttools>=4.22.0\n",
            "  Using cached fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in ./env/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
            "Collecting pillow>=6.2.0\n",
            "  Downloading Pillow-9.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
            "  Using cached kiwisolver-1.4.4-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "Requirement already satisfied: numpy>=1.19 in ./env/lib/python3.10/site-packages (from matplotlib) (1.23.4)\n",
            "Requirement already satisfied: six>=1.5 in ./env/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Installing collected packages: pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
            "Successfully installed contourpy-1.0.6 cycler-0.11.0 fonttools-4.38.0 kiwisolver-1.4.4 matplotlib-3.6.2 pillow-9.3.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LxF8vk2MqeJa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-11-11 19:34:32.715852: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-11-11 19:34:32.842865: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2022-11-11 19:34:32.848267: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/kmh/Desktop/SEM7/DL/proj-test/env/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2022-11-11 19:34:32.848288: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2022-11-11 19:34:32.875409: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-11-11 19:34:33.555159: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/kmh/Desktop/SEM7/DL/proj-test/env/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2022-11-11 19:34:33.555233: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/kmh/Desktop/SEM7/DL/proj-test/env/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2022-11-11 19:34:33.555239: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQNxUsoEseeA",
        "outputId": "a06a943d-6ac1-4777-a1b9-016d0acd085d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3081\n"
          ]
        }
      ],
      "source": [
        "from keras.utils.text_dataset import text_dataset_from_directory\n",
        "path=\"/home/kmh/Desktop/newdataset\"\n",
        "dataset=os.listdir(path)\n",
        "train_files=[]\n",
        "test_files=[]\n",
        "all=['normal-grayscale-resized', 'dme-grayscale-resized', 'amd-grayscale-resized']\n",
        "\n",
        "\n",
        "for folder in all:\n",
        "  for eachfile in os.listdir(f\"{path}/training/{folder}\"):\n",
        "    img=cv.imread(f\"{path}/training/{folder}/{eachfile}\")\n",
        "    img=cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
        "    img=cv.resize(img,[32,32],interpolation=cv.INTER_AREA)\n",
        "    train_files.append(img)\n",
        "print(len(train_files))\n",
        "\n",
        "\n",
        "for folder in all:\n",
        "  for eachfile in os.listdir(f\"{path}/testing/{folder}\"):\n",
        "    img=cv.imread(f\"{path}/testing/{folder}/{eachfile}\")\n",
        "    img=cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
        "    img=cv.resize(img,[32,32],interpolation=cv.INTER_AREA)\n",
        "    test_files.append(img)\n",
        "\n",
        "    \n",
        "y_test=[]\n",
        "y_train=[]\n",
        "for i in range(len(all)):\n",
        "  for eachfile in os.listdir(f\"{path}/testing/{all[i]}\"):\n",
        "    y_test.append(i)\n",
        "# print(y_test)\n",
        "    \n",
        "\n",
        "for i in range(len(all)):\n",
        "  # print(os.listdir(f\"{path}/testing/{folder}\"))\n",
        "  for eachfile in os.listdir(f\"{path}/training/{all[i]}\"):\n",
        "    y_train.append(i)\n",
        "\n",
        "# print(len(y_train))\n",
        "\n",
        "# for folder in all:\n",
        "#   # print(os.listdir(f\"{path}/testing/{folder}\"))\n",
        "#   for eachfile in os.listdir(f\"{path}/testing/{folder}\"):\n",
        "#     test_files.append(eachfile)\n",
        "    \n",
        "# print(len(test_files))\n",
        "      # train_files.append(os.listdir(f\"{path}/{each}/{every}\"))\n",
        "      # test_files.append(os.listdir(f\"{path}/{each}/{every}\"))\n",
        "    # cv.imwrite(f\"{path}/testing/{folder}-grayscale/{eachfile}\",im_gray)\n",
        "# print(len(test_files))\n",
        "      # train_files.append(os.listdir(f\"{path}/{each}/{every}\"))\n",
        "      # test_files.append(os.listdir(f\"{path}/{each}/{every}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgpO5rCPqvbK",
        "outputId": "258d8ef7-36b0-4c64-d4c1-1efd57d0beb1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(32, 32)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# train_path=f\"\"\n",
        "# path=\"/content/gdrive/MyDrive/newdataset\"\n",
        "img=train_files[0]\n",
        "img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bm3uxpeqnQP"
      },
      "outputs": [],
      "source": [
        "# from tensorflow import keras\n",
        "\n",
        "# X_train = keras.utils.image_dataset_from_directory(\n",
        "#     directory=f'{path}/training/',\n",
        "#     labels='inferred',\n",
        "#     label_mode='categorical',\n",
        "#     batch_size=32,\n",
        "#     image_size=(496, 512))\n",
        "\n",
        "# X_test = keras.utils.image_dataset_from_directory(\n",
        "#     directory=f'{path}/testing/',\n",
        "#     labels='inferred',\n",
        "#     label_mode='categorical',\n",
        "#     batch_size=32,\n",
        "#     image_size=(496, 512))\n",
        "# print(X_train,X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "5fGaEXCBrZZJ"
      },
      "outputs": [],
      "source": [
        "from __future__ import division\n",
        "\n",
        "import six\n",
        "from keras.models import Model\n",
        "from keras.layers import (\n",
        "    Input,\n",
        "    Activation,\n",
        "    Dense,\n",
        "    Flatten\n",
        ")\n",
        "from keras.layers.convolutional import (\n",
        "    Conv2D,\n",
        "    MaxPooling2D,\n",
        "    AveragePooling2D\n",
        ")\n",
        "from keras.layers import add\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "def _bn_relu(input):\n",
        "    \"\"\"Helper to build a BN -> relu block\n",
        "    \"\"\"\n",
        "    norm = BatchNormalization(axis=CHANNEL_AXIS)(input)\n",
        "    return Activation(\"relu\")(norm)\n",
        "\n",
        "\n",
        "def _conv_bn_relu(**conv_params):\n",
        "    \"\"\"Helper to build a conv -> BN -> relu block\n",
        "    \"\"\"\n",
        "    filters = conv_params[\"filters\"]\n",
        "    kernel_size = conv_params[\"kernel_size\"]\n",
        "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
        "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
        "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
        "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
        "\n",
        "    def f(input):\n",
        "        conv = Conv2D(filters=filters, kernel_size=kernel_size,\n",
        "                      strides=strides, padding=padding,\n",
        "                      kernel_initializer=kernel_initializer,\n",
        "                      kernel_regularizer=kernel_regularizer)(input)\n",
        "        return _bn_relu(conv)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def _bn_relu_conv(**conv_params):\n",
        "    \"\"\"Helper to build a BN -> relu -> conv block.\n",
        "    This is an improved scheme proposed in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "    \"\"\"\n",
        "    filters = conv_params[\"filters\"]\n",
        "    kernel_size = conv_params[\"kernel_size\"]\n",
        "    strides = conv_params.setdefault(\"strides\", (1, 1))\n",
        "    kernel_initializer = conv_params.setdefault(\"kernel_initializer\", \"he_normal\")\n",
        "    padding = conv_params.setdefault(\"padding\", \"same\")\n",
        "    kernel_regularizer = conv_params.setdefault(\"kernel_regularizer\", l2(1.e-4))\n",
        "\n",
        "    def f(input):\n",
        "        activation = _bn_relu(input)\n",
        "        return Conv2D(filters=filters, kernel_size=kernel_size,\n",
        "                      strides=strides, padding=padding,\n",
        "                      kernel_initializer=kernel_initializer,\n",
        "                      kernel_regularizer=kernel_regularizer)(activation)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def _shortcut(input, residual):\n",
        "    \"\"\"Adds a shortcut between input and residual block and merges them with \"sum\"\n",
        "    \"\"\"\n",
        "    # Expand channels of shortcut to match residual.\n",
        "    # Stride appropriately to match residual (width, height)\n",
        "    # Should be int if network architecture is correctly configured.\n",
        "    input_shape = K.int_shape(input)\n",
        "    residual_shape = K.int_shape(residual)\n",
        "    stride_width = int(round(input_shape[ROW_AXIS] / residual_shape[ROW_AXIS]))\n",
        "    stride_height = int(round(input_shape[COL_AXIS] / residual_shape[COL_AXIS]))\n",
        "    equal_channels = input_shape[CHANNEL_AXIS] == residual_shape[CHANNEL_AXIS]\n",
        "\n",
        "    shortcut = input\n",
        "    # 1 X 1 conv if shape is different. Else identity.\n",
        "    if stride_width > 1 or stride_height > 1 or not equal_channels:\n",
        "        shortcut = Conv2D(filters=residual_shape[CHANNEL_AXIS],\n",
        "                          kernel_size=(1, 1),\n",
        "                          strides=(2,1),\n",
        "                          # strides=(stride_width, stride_height),\n",
        "                          padding=\"valid\",\n",
        "                          kernel_initializer=\"he_normal\",\n",
        "                          kernel_regularizer=l2(0.0001))(input)\n",
        "\n",
        "    return add([shortcut, residual])\n",
        "\n",
        "\n",
        "def _residual_block(block_function, filters, repetitions, is_first_layer=False):\n",
        "    \"\"\"Builds a residual block with repeating bottleneck blocks.\n",
        "    \"\"\"\n",
        "    def f(input):\n",
        "        for i in range(repetitions):\n",
        "            init_strides = (1, 1)\n",
        "            if i == 0 and not is_first_layer:\n",
        "                init_strides = (2, 2)\n",
        "            input = block_function(filters=filters, init_strides=init_strides,\n",
        "                                   is_first_block_of_first_layer=(is_first_layer and i == 0))(input)\n",
        "        return input\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def basic_block(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
        "    \"\"\"Basic 3 X 3 convolution blocks for use on resnets with layers <= 34.\n",
        "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "    \"\"\"\n",
        "    def f(input):\n",
        "\n",
        "        if is_first_block_of_first_layer:\n",
        "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
        "            conv1 = Conv2D(filters=filters, kernel_size=(3, 3),\n",
        "                           strides=init_strides,\n",
        "                           padding=\"same\",\n",
        "                           kernel_initializer=\"he_normal\",\n",
        "                           kernel_regularizer=l2(1e-4))(input)\n",
        "        else:\n",
        "            conv1 = _bn_relu_conv(filters=filters, kernel_size=(3, 3),\n",
        "                                  strides=init_strides)(input)\n",
        "\n",
        "        residual = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv1)\n",
        "        return _shortcut(input, residual)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def bottleneck(filters, init_strides=(1, 1), is_first_block_of_first_layer=False):\n",
        "    \"\"\"Bottleneck architecture for > 34 layer resnet.\n",
        "    Follows improved proposed scheme in http://arxiv.org/pdf/1603.05027v2.pdf\n",
        "    Returns:\n",
        "        A final conv layer of filters * 4\n",
        "    \"\"\"\n",
        "    def f(input):\n",
        "\n",
        "        if is_first_block_of_first_layer:\n",
        "            # don't repeat bn->relu since we just did bn->relu->maxpool\n",
        "            conv_1_1 = Conv2D(filters=filters, kernel_size=(1, 1),\n",
        "                              strides=init_strides,\n",
        "                              padding=\"same\",\n",
        "                              kernel_initializer=\"he_normal\",\n",
        "                              kernel_regularizer=l2(1e-4))(input)\n",
        "        else:\n",
        "            conv_1_1 = _bn_relu_conv(filters=filters, kernel_size=(1, 1),\n",
        "                                     strides=init_strides)(input)\n",
        "\n",
        "        conv_3_3 = _bn_relu_conv(filters=filters, kernel_size=(3, 3))(conv_1_1)\n",
        "        residual = _bn_relu_conv(filters=filters * 4, kernel_size=(1, 1))(conv_3_3)\n",
        "        return _shortcut(input, residual)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def _handle_dim_ordering():\n",
        "    global ROW_AXIS\n",
        "    global COL_AXIS\n",
        "    global CHANNEL_AXIS\n",
        "    if K.image_data_format() == 'tf':\n",
        "        ROW_AXIS = 1\n",
        "        COL_AXIS = 2\n",
        "        CHANNEL_AXIS = 3\n",
        "    else:\n",
        "        CHANNEL_AXIS = 1\n",
        "        ROW_AXIS = 2\n",
        "        COL_AXIS = 3\n",
        "\n",
        "\n",
        "def _get_block(identifier):\n",
        "    if isinstance(identifier, six.string_types):\n",
        "        res = globals().get(identifier)\n",
        "        if not res:\n",
        "            raise ValueError('Invalid {}'.format(identifier))\n",
        "        return res\n",
        "    return identifier\n",
        "\n",
        "\n",
        "class ResnetBuilder(object):\n",
        "    @staticmethod\n",
        "    def build(input_shape, num_outputs, block_fn, repetitions):\n",
        "        \"\"\"Builds a custom ResNet like architecture.\n",
        "        Args:\n",
        "            input_shape: The input shape in the form (nb_channels, nb_rows, nb_cols)\n",
        "            num_outputs: The number of outputs at final softmax layer\n",
        "            block_fn: The block function to use. This is either `basic_block` or `bottleneck`.\n",
        "                The original paper used basic_block for layers < 50\n",
        "            repetitions: Number of repetitions of various block units.\n",
        "                At each block unit, the number of filters are doubled and the input size is halved\n",
        "        Returns:\n",
        "            The keras `Model`.\n",
        "        \"\"\"\n",
        "        _handle_dim_ordering()\n",
        "        if len(input_shape) != 3:\n",
        "            raise Exception(\"Input shape should be a tuple (nb_channels, nb_rows, nb_cols)\")\n",
        "\n",
        "        # Permute dimension order if necessary\n",
        "        if K.image_data_format() == 'tf':\n",
        "            input_shape = (input_shape[1], input_shape[2], input_shape[0])\n",
        "\n",
        "        # Load function from str if needed.\n",
        "        block_fn = _get_block(block_fn)\n",
        "\n",
        "        input = Input(shape=input_shape)\n",
        "        conv1 = _conv_bn_relu(filters=64, kernel_size=(7, 7), strides=(2, 2))(input)\n",
        "        pool1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding=\"same\")(conv1)\n",
        "\n",
        "        block = pool1\n",
        "        filters = 64\n",
        "        for i, r in enumerate(repetitions):\n",
        "            block = _residual_block(block_fn, filters=filters, repetitions=r, is_first_layer=(i == 0))(block)\n",
        "            filters *= 2\n",
        "\n",
        "        # Last activation\n",
        "        block = _bn_relu(block)\n",
        "\n",
        "        # Classifier block\n",
        "        block_shape = K.int_shape(block)\n",
        "        pool2 = AveragePooling2D(pool_size=(block_shape[ROW_AXIS], block_shape[COL_AXIS]),\n",
        "                                 strides=(1, 1))(block)\n",
        "        flatten1 = Flatten()(pool2)\n",
        "        dense = Dense(units=num_outputs, kernel_initializer=\"he_normal\",\n",
        "                      activation=\"softmax\")(flatten1)\n",
        "\n",
        "        model = Model(inputs=input, outputs=dense)\n",
        "        return model\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_18(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [2, 2, 2, 2])\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_34(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, basic_block, [3, 4, 6, 3])\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_50(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 6, 3])\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_101(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "    @staticmethod\n",
        "    def build_resnet_152(input_shape, num_outputs):\n",
        "        return ResnetBuilder.build(input_shape, num_outputs, bottleneck, [3, 8, 36, 3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "VOv_KtVJkIIZ"
      },
      "outputs": [],
      "source": [
        "train_files=np.array(train_files)\n",
        "test_files=np.array(test_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urNhz7J4laP0",
        "outputId": "d4cad878-fcfa-42e1-c69b-8f0b15c1e188"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3081, 32, 32)\n"
          ]
        }
      ],
      "source": [
        "print(train_files.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "IPvJLO2BY238",
        "outputId": "4cb278f0-48e5-4c74-d2fc-3014f91e77d1"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Inputs have incompatible shapes. Received shapes (1, 8, 1) and (1, 4, 128)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [24], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m train_files \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39m128.\u001b[39m\n\u001b[1;32m     30\u001b[0m test_files \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m \u001b[39m128.\u001b[39m\n\u001b[0;32m---> 32\u001b[0m model \u001b[39m=\u001b[39m ResnetBuilder\u001b[39m.\u001b[39;49mbuild_resnet_18((img_channels, img_rows, img_cols), nb_classes)\n\u001b[1;32m     33\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     34\u001b[0m               optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     35\u001b[0m               metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     37\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m data_augmentation:\n",
            "Cell \u001b[0;32mIn [21], line 234\u001b[0m, in \u001b[0;36mResnetBuilder.build_resnet_18\u001b[0;34m(input_shape, num_outputs)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    233\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_resnet_18\u001b[39m(input_shape, num_outputs):\n\u001b[0;32m--> 234\u001b[0m     \u001b[39mreturn\u001b[39;00m ResnetBuilder\u001b[39m.\u001b[39;49mbuild(input_shape, num_outputs, basic_block, [\u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m])\n",
            "Cell \u001b[0;32mIn [21], line 215\u001b[0m, in \u001b[0;36mResnetBuilder.build\u001b[0;34m(input_shape, num_outputs, block_fn, repetitions)\u001b[0m\n\u001b[1;32m    213\u001b[0m filters \u001b[39m=\u001b[39m \u001b[39m64\u001b[39m\n\u001b[1;32m    214\u001b[0m \u001b[39mfor\u001b[39;00m i, r \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(repetitions):\n\u001b[0;32m--> 215\u001b[0m     block \u001b[39m=\u001b[39m _residual_block(block_fn, filters\u001b[39m=\u001b[39;49mfilters, repetitions\u001b[39m=\u001b[39;49mr, is_first_layer\u001b[39m=\u001b[39;49m(i \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m))(block)\n\u001b[1;32m    216\u001b[0m     filters \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m    218\u001b[0m \u001b[39m# Last activation\u001b[39;00m\n",
            "Cell \u001b[0;32mIn [21], line 104\u001b[0m, in \u001b[0;36m_residual_block.<locals>.f\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_first_layer:\n\u001b[1;32m    103\u001b[0m         init_strides \u001b[39m=\u001b[39m (\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[0;32m--> 104\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m block_function(filters\u001b[39m=\u001b[39;49mfilters, init_strides\u001b[39m=\u001b[39;49minit_strides,\n\u001b[1;32m    105\u001b[0m                            is_first_block_of_first_layer\u001b[39m=\u001b[39;49m(is_first_layer \u001b[39mand\u001b[39;49;00m i \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m))(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    106\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
            "Cell \u001b[0;32mIn [21], line 129\u001b[0m, in \u001b[0;36mbasic_block.<locals>.f\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m    125\u001b[0m     conv1 \u001b[39m=\u001b[39m _bn_relu_conv(filters\u001b[39m=\u001b[39mfilters, kernel_size\u001b[39m=\u001b[39m(\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m),\n\u001b[1;32m    126\u001b[0m                           strides\u001b[39m=\u001b[39minit_strides)(\u001b[39minput\u001b[39m)\n\u001b[1;32m    128\u001b[0m residual \u001b[39m=\u001b[39m _bn_relu_conv(filters\u001b[39m=\u001b[39mfilters, kernel_size\u001b[39m=\u001b[39m(\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m))(conv1)\n\u001b[0;32m--> 129\u001b[0m \u001b[39mreturn\u001b[39;00m _shortcut(\u001b[39minput\u001b[39;49m, residual)\n",
            "Cell \u001b[0;32mIn [21], line 93\u001b[0m, in \u001b[0;36m_shortcut\u001b[0;34m(input, residual)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mif\u001b[39;00m stride_width \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m stride_height \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m equal_channels:\n\u001b[1;32m     85\u001b[0m     shortcut \u001b[39m=\u001b[39m Conv2D(filters\u001b[39m=\u001b[39mresidual_shape[CHANNEL_AXIS],\n\u001b[1;32m     86\u001b[0m                       kernel_size\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m),\n\u001b[1;32m     87\u001b[0m                       strides\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m                       kernel_initializer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhe_normal\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     91\u001b[0m                       kernel_regularizer\u001b[39m=\u001b[39ml2(\u001b[39m0.0001\u001b[39m))(\u001b[39minput\u001b[39m)\n\u001b[0;32m---> 93\u001b[0m \u001b[39mreturn\u001b[39;00m add([shortcut, residual])\n",
            "File \u001b[0;32m~/Desktop/SEM7/DL/proj-test/env/lib/python3.10/site-packages/keras/layers/merging/add.py:92\u001b[0m, in \u001b[0;36madd\u001b[0;34m(inputs, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39m@keras_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mkeras.layers.add\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madd\u001b[39m(inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m     \u001b[39m\"\"\"Functional interface to the `tf.keras.layers.Add` layer.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m \n\u001b[1;32m     91\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m     \u001b[39mreturn\u001b[39;00m Add(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)(inputs)\n",
            "File \u001b[0;32m~/Desktop/SEM7/DL/proj-test/env/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/Desktop/SEM7/DL/proj-test/env/lib/python3.10/site-packages/keras/layers/merging/base_merge.py:74\u001b[0m, in \u001b[0;36m_Merge._compute_elemwise_op_output_shape\u001b[0;34m(self, shape1, shape2)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m         \u001b[39mif\u001b[39;00m i \u001b[39m!=\u001b[39m j:\n\u001b[0;32m---> 74\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     75\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mInputs have incompatible shapes. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     76\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived shapes \u001b[39m\u001b[39m{\u001b[39;00mshape1\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00mshape2\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         output_shape\u001b[39m.\u001b[39mappend(i)\n\u001b[1;32m     79\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(output_shape)\n",
            "\u001b[0;31mValueError\u001b[0m: Inputs have incompatible shapes. Received shapes (1, 8, 1) and (1, 4, 128)"
          ]
        }
      ],
      "source": [
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
        "early_stopper = EarlyStopping(min_delta=0.001, patience=10)\n",
        "csv_logger = CSVLogger('resnet18_oct.csv')\n",
        "\n",
        "batch_size = 32\n",
        "nb_classes = 3\n",
        "nb_epoch = 100\n",
        "data_augmentation = False\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 32,32\n",
        "\n",
        "img_channels = 3\n",
        "\n",
        "# The data, shuffled and split between train and test sets:\n",
        "# (train_files, y_train), (test_files, y_test)\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
        "\n",
        "train_files = train_files.astype('float32')\n",
        "test_files = test_files.astype('float32')\n",
        "\n",
        "# subtract mean and normalize\n",
        "mean_image = np.mean(train_files, axis=0)\n",
        "train_files -= mean_image\n",
        "test_files -= mean_image\n",
        "train_files /= 128.\n",
        "test_files /= 128.\n",
        "\n",
        "model = ResnetBuilder.build_resnet_18((img_channels, img_rows, img_cols), nb_classes)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(train_files, Y_train,\n",
        "              batch_size=batch_size,\n",
        "              nb_epoch=nb_epoch,\n",
        "              validation_data=(test_files, Y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=[lr_reducer, early_stopper, csv_logger])\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "    # Compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(train_files)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model.fit_generator(datagen.flow(train_files, Y_train, batch_size=batch_size),\n",
        "                        steps_per_epoch=train_files.shape[0] // batch_size,\n",
        "                        validation_data=(test_files, Y_test),\n",
        "                        epochs=nb_epoch, verbose=1, max_q_size=100,\n",
        "                        callbacks=[lr_reducer, early_stopper, csv_logger])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.11.0rc1 ('env': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "b3860b29b9db5bc4a29043adf5b0cc45202791962b1260ffb7220e148e44d15a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
